{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the difference between a NumPy array and a list?\n",
    "\n",
    "1. What is the difference between a NumPy array and a list?\n",
    "\n",
    "    We'll cover some common questions about scientific computing in Python. We'll start with NumPy arrays and compare them to Python lists.\n",
    "\n",
    "2. NumPy array\n",
    "\n",
    "    It is a special data structure from the NumPy module representing a fundamental package for scientific computing with Python. The easiest way to create an array is to pass a list of values to the array() constructor. At the first glance, there isn't a big difference to Python's native lists.\n",
    "\n",
    "3. Similarities between an array and a list\n",
    "\n",
    "    Both data structures are Iterables. In both cases we can use indexing to access elements. \n",
    "\n",
    "    Moreover, NumPy arrays and Python lists can be modified similarly. What's so special about NumPy arrays then?\n",
    "\n",
    "    Compared to lists, NumPy arrays are optimized for high efficiency computations. How? First of all, NumPy arrays only store data of the same type.\n",
    "\n",
    "4. dtype property\n",
    "    \n",
    "    When we have an array, we can retrieve the data type it stores by accessing its .dtype property. In this case, our array stores integers represented by 64 bits.\n",
    "\n",
    "8. Changing the data type of an element\n",
    "    \n",
    "    Compared to lists, if we try to modify an element with a different data type, we'll get ValueError.\n",
    "\n",
    "9. Specifying the data type explicitly\n",
    "    \n",
    "    Actually, we can explicitly specify the data type when we create an array using the dtype keyword argument.\n",
    "\n",
    "    Independently from the list we pass, we can specify other data types like a string, for example. The output we see here means a one-character string.\n",
    "\n",
    "        num_array = np.array([1,2,3,4,5], dtype=np.type('str'))\n",
    "        num_array.dtype\n",
    "        > dtype('<U1')\n",
    "\n",
    "11. Object as a data type\n",
    "\n",
    "    If we want an array to behave like a list with respect to modification, we can use the dtype equal to 'O' which stands for Object. In this case, we can mix data types. However, we also limit the set of operations we can apply to such an array.\n",
    "\n",
    "        num_array = np.array([1,2,3,4,5], dtype = np.dtype('O'))\n",
    "    \n",
    "12. Difference between an array and a list - Accessing items\n",
    "    \n",
    "    The second property of NumPy arrays is that they offer a special way to access their elements.\n",
    "    \n",
    "    Let's assume we have this two-dimensional list. As an array it can be defined like this. To retrieve a single item, say the 8 in this case, both lists and arrays provide similar options.\n",
    "\n",
    "        array2d = np.array([\n",
    "            [1,2,3,4,5],\n",
    "            [6,7,8,9,10],\n",
    "            [11,12,13,14,15]\n",
    "        ])\n",
    "\n",
    "14. Accessing items\n",
    "\n",
    "    With arrays though, it's not necessary to specify additional square brackets.\n",
    "\n",
    "        # Retrieve 8\n",
    "        array2d[1,2]\n",
    "        > 8\n",
    "\n",
    "    But how do we retrieve an entire data block?\n",
    "\n",
    "    The solution for a list can be tricky.\n",
    "\n",
    "    An array provides a more elegant and efficient way via slicing.\n",
    "\n",
    "        array2d[0:2,1:4]\n",
    "        > array([2,3,4],\n",
    "                [7,8,9])\n",
    "\n",
    "18. Difference between an array and a list\n",
    "\n",
    "    Third, operations work differently on arrays. For simplicity, we'll focus only on numeric arrays.\n",
    "\n",
    "19. Operations +, -, *, / with lists\n",
    "\n",
    "    Let's recall that, given two lists, most of the simple mathematical operations will result in TypeError. Addition is an exception; it concatenates given lists.\n",
    "\n",
    "    In case of NumPy arrays, operations are performed element-wise. As a result, we get a new array.\n",
    "\n",
    "        num_array1 = np.array([1,2,3])\n",
    "        num_array2 = np.array([10,20,30])\n",
    "        num_array1 + num_array2\n",
    "        > array([11,22,33])\n",
    "        num_array1*num_array2\n",
    "        > array([10,40,90])\n",
    "\n",
    "    The same applies to multidimensional arrays.\n",
    "\n",
    "22. Conditional operations\n",
    "\n",
    "    Conditional operations are especially useful. Applying them on an array returns a new array of booleans indicating whether the condition is satisfied or not. The cool part is that we can use these conditions to filter our arrays. This operation takes much more effort with lists.\n",
    "\n",
    "        num_array = np.array([-5,-4,-3,0,3,4,5])\n",
    "        num_array[num_array <0]\n",
    "        > array([-5,-4,-3])\n",
    "\n",
    "23. Broadcasting\n",
    "\n",
    "    Another important feature of arrays is broadcasting. It describes how operations work on arrays of different dimensions. For example, what happens if we multiply this array by 3? We certainly know the answer for lists: they get extended. In case of arrays, each element is multiplied by 3 resulting in a new array. The same applies to other operations. We say that 3 broadcasts itself to all the array elements meaning that 3 operates on each element separately.\n",
    "        \n",
    "        num_list = [1,2,3]\n",
    "        num_list * 3\n",
    "        > [1,2,3,1,2,3,1,2,3]\n",
    "        \n",
    "        num_array = np.array([1,2,3])\n",
    "        num_array * 3\n",
    "        > array([3,6,9])\n",
    "\n",
    "\n",
    "24. Broadcasting with multidimensional arrays\n",
    "\n",
    "    We can do broadcasting with multidimensional arrays. For this example, the one-dimensional array broadcasts itself to all three rows of the two-dimensional array. Broadcasting is applied to rows by default. If we want to broadcast to columns, we need to modify our one-dimensional array to be a column vector. And here's the result.\n",
    "\n",
    "        array1d = np.array([[1], [2], [3]])\n",
    "        \n",
    "26. Let's practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# What is the type of the following array?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# What is the type of the following array?\n",
    "np.array([1,(2,3),4]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing subarrays\n",
    "\n",
    "Let's access elements in NumPy arrays! Your task is to convert a square two-dimensional array square of size size to a list created by following a spiral pattern:\n",
    "\n",
    "Traversing the matrix in spiral way\n",
    "\n",
    "Rather than simply accessing certain slices, you will define a more general solution using a for loop (the solution should work for all the square two-dimensional arrays of odd size).\n",
    "\n",
    "The module numpy is already imported as np.\n",
    "\n",
    "You will need the reversed() function, which reverses an Iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = np.array([[ 1,  2,  3,  4,  5],\n",
    "       [ 6,  7,  8,  9, 10],\n",
    "       [11, 12, 13, 14, 15],\n",
    "       [16, 17, 18, 19, 20],\n",
    "       [21, 22, 23, 24, 25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 10, 15, 20, 25, 24, 23, 22, 21, 16, 11, 6, 7, 8, 9, 14, 19, 18, 17, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "spiral = []\n",
    "size = len(square)\n",
    "\n",
    "for i in range(0, size):\n",
    "    # Convert each part marked by a red arrow to a list\n",
    "    spiral += list(square[i, i:size-i])\n",
    "    # Convert each part marked by a green arrow to a list\n",
    "    spiral += list(square[i+1:size-i, size-i-1])\n",
    "    # Convert each part marked by a blue arrow to a list\n",
    "    spiral += list(reversed(square[size-i-1, i:size-i-1]))\n",
    "    # Convert each part marked by a magenta arrow to a list\n",
    "    spiral += list(reversed(square[i+1:size-i-1, i]))\n",
    "        \n",
    "print(spiral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with NumPy arrays\n",
    "\n",
    "The following blocks of code create new lists given input lists input_list1, input_list2, input_list3 (you can check their values in the console). If you had analogous NumPy arrays with the same values input_array1, input_array2, input_array3 (you can check their values in the console), how would you create similar output as NumPy arrays using the knowledge on broadcasting, accessing element in NumPy arrays, and performing element-wise operations?\n",
    "\n",
    "Block 1\n",
    "\n",
    "list(map(lambda x: [5*i for i in x], input_list1))\n",
    "\n",
    "Block 2\n",
    "\n",
    "list(filter(lambda x: x % 2 == 0, input_list2))\n",
    "\n",
    "Block 3\n",
    "\n",
    "[[i*i for i in j] for j in input_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array1 = np.array([[1, 2, 3],\n",
    "       [4, 5, 6],\n",
    "       [7, 8, 9]])\n",
    "input_array2 = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "input_array3 = np.array([[1, 2],\n",
    "       [3, 4],\n",
    "       [5, 6]])\n",
    "\n",
    "input_list1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "input_list2 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "input_list3 = [[1, 2], [3, 4], [5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 10, 15], [20, 25, 30], [35, 40, 45]]\n",
      "[[ 5 10 15]\n",
      " [20 25 30]\n",
      " [35 40 45]]\n"
     ]
    }
   ],
   "source": [
    "# Substitute the code in the block 1 given the input_array1\n",
    "output_array1 = input_array1 * 5 \n",
    "print(list(map(lambda x: [5*i for i in x], input_list1)))\n",
    "print(output_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8]\n",
      "[0 2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "# Substitute the code in the block 2 given the input_array2\n",
    "output_array2 = input_array2[ input_array2 % 2 == 0]\n",
    "print(list(filter(lambda x: x % 2 == 0, input_list2)))\n",
    "print(output_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4], [9, 16], [25, 36]]\n",
      "[[ 1  4]\n",
      " [ 9 16]\n",
      " [25 36]]\n"
     ]
    }
   ],
   "source": [
    "# Substitute the code in the block 3 given the input_array3\n",
    "output_array3 = input_array3 * input_array3\n",
    "print([[i*i for i in j] for j in input_list3])\n",
    "print(output_array3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the .apply() method on a DataFrame?\n",
    "\n",
    "1. How to use the .apply() method on a DataFrame?\n",
    "\n",
    "    Let's move to DataFrames! We'll cover one of the most frequently used methods, .apply().\n",
    "\n",
    "2. Dataset\n",
    "\n",
    "    First, let's pick a dataset. We'll work with data on 100 students and their performance on different subjects. Each performance score varies between 0 and 100.\n",
    "\n",
    "3. Default .apply()\n",
    "\n",
    "    Let's use the .apply() method. It requires one argument - a function that, by default, is applied on each column of a DataFrame. However, the output of .apply() may differ. For example, applying the sqrt() function results in a DataFrame with square roots of original values.\n",
    "        \n",
    "        scores_new = scores.apply(np.sqrt)\n",
    "\n",
    "4. Default .apply()\n",
    "\n",
    "    However, using the mean() function returns a Series. Why?\n",
    "\n",
    "        scores_new = scores.apply(np.mean)\n",
    "        type(scores_new)\n",
    "            > pandas.core.series.Series\n",
    "\n",
    "    The columns we apply the function to are passed as pandas Series. When we use sqrt(), we simply modify each value in a column and return an object of the same size. When we use mean(), we summarize the Series with a single value.\n",
    "\n",
    "    For example, let's define a function halving our scores. We get a modified DataFrame because passing columns to our defined function results in an object of the same size.\n",
    "\n",
    "    On the contrary, if we return only one value - for example, a perfect score - we summarize each column by a single value. Therefore, we get pandas Series.\n",
    "\n",
    "8. Lambda expressions\n",
    "\n",
    "    Of course, our functions can be substituted with lambda expressions!\n",
    "\n",
    "        scores_new = scores.apply(lambda x: x/2)\n",
    "\n",
    "    It will simplify our code with no changes in our output.\n",
    "\n",
    "10. Additional arguments: axis\n",
    "\n",
    "    Let's have a look at additional arguments we can pass to the .apply() method. We'll start with the axis argument. which can be either 0, which is default, or 1.\n",
    "\n",
    "        df.apply(function, axis= )\n",
    "        axis=0, over columns (default)\n",
    "        axis=1, over rows\n",
    "        \n",
    "    0 means that the function is applied over the columns of a DataFrame, 1 - over the rows. Specifying this argument is useful for functions resulting in a single value like mean().\n",
    "\n",
    "    Zero implies no difference from the default behavior: we get the mean of each column. 1 implies averaging values in each row instead.\n",
    "\n",
    "16. Additional arguments: result_type\n",
    "\n",
    "    The next argument we'll discuss is result_type. We'll consider only some of the values it can take. The first one is expand. To understand it, let's define a function that returns a list with the minimum and the maximum value of the input. When we apply the function to the DataFrame, we get a pandas Series with the corresponding summary for each column. Notice that the list returned by the span() function is considered as a single value summarizing our input, despite the fact that its size is 2. Therefore, the .apply() method results in a pandas Series.\n",
    "\n",
    "        df.apply(function, result_type= )\n",
    "        result_type='expand'\n",
    "\n",
    "    Specifying the keyword argument unwraps our list resulting in the following DataFrame.\n",
    "\n",
    "    Adding the axis argument and setting it to 1 applies the span() function row-wise and unfolds the list for each row.\n",
    "\n",
    "    The second useful value for result_type is broadcast. To understand it, let's consider applying the mean() function again.\n",
    "\n",
    "        result_type='broadcast'\n",
    "\n",
    "    Specifying broadcasting results in a DataFrame of the original size where each column is filled with the corresponding output from the mean() function.\n",
    "\n",
    "21. More than one argument in a function\n",
    "\n",
    "    So far, our functions we used .apply() with had only one argument.But what if we have more arguments including keyword arguments? For example, let's have a function that by default checks if the calculated mean is within a certain interval. If the value of the keyword argument changes to False, then we check an opposite scenario.\n",
    "\n",
    "        df.apply(function, args= )\n",
    "        args = [arg1,arg2,..]\n",
    "\n",
    "        \n",
    "23. Applying the function\n",
    "\n",
    "    Let's use .apply() with our function. We get TypeError because we didn't specify its arguments!\n",
    "\n",
    "24. Additional arguments: args\n",
    "\n",
    "    They can be specified in the args argument of the .apply() method. It's a list containing positional arguments for our function. Let's try it now. It works! Notice, the values in the list should have the same order as the function arguments. We didn't specify the 'inside' keyword argument, so the function executes with its default value. What if we want to pass another value?\n",
    "\n",
    "    We can simply insert it afterwards. As expected, setting it to False produces an inverted result.\n",
    "\n",
    "26. Let's practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple use of .apply()\n",
    "\n",
    "Let's get some handful experience with .apply()!\n",
    "\n",
    "You are given the full scores dataset containing students' performance as well as their background information.\n",
    "\n",
    "Your task is to define the prevalence() function and apply it to the groups_to_consider columns of the scores DataFrame. This function should retrieve the most prevalent group/category for a given column (e.g. if the most prevalent category in the lunch column is standard, then prevalence() should return standard).\n",
    "\n",
    "The reduce() function from the functools module is already imported.\n",
    "\n",
    "Tip: pd.Series is an Iterable object. Therefore, you can use standard operations on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def prevalence(series):\n",
    "    vals = list(series)\n",
    "    # Create a tuple list with unique items and their counts\n",
    "    itms = [(x, vals.count(x)) for x in set(vals)]\n",
    "    # Extract a tuple with the highest counts using reduce()\n",
    "    res = reduce(lambda x, y: x if x[1]>=y[1] else y, itms)\n",
    "    # Return the item with the highest counts\n",
    "    return res[0]\n",
    "\n",
    "# Apply the prevalence function on the scores DataFrame\n",
    "result = scores[groups_to_consider].apply(prevalence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional arguments\n",
    "\n",
    "Let's use additional arguments in the .apply() method!\n",
    "\n",
    "Your task is to create two new columns in scores:\n",
    "\n",
    "- mean is the row-wise mean value of the math score, reading score and writing score\n",
    "- rank defines how high the mean score is:\n",
    "    - 'high' if the mean value \n",
    "    - 'medium' if the mean value > 60 but <= 90\n",
    "    - 'low' if the mean value \n",
    "\n",
    "To accomplish this task, you'll need to define the function rank that, given a series, returns a list with two values: the mean of the series and a string defined by the aforementioned rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def rank(series):\n",
    "    # Calculate the mean of the input series\n",
    "    mean = series.mean()\n",
    "    # Return the mean and its rank as a list\n",
    "    if mean > 90:\n",
    "        return [mean,'high']\n",
    "    elif mean > 60:\n",
    "        return [mean,'medium']\n",
    "    else:\n",
    "        return [mean,'low']\n",
    "\n",
    "# Insert the output of rank() into new columns of scores\n",
    "cols = ['math score', 'reading score', 'writing score']\n",
    "scores[['mean', 'rank']] = scores[cols].apply(rank, result_type = 'expand', axis=1)\n",
    "print(scores[['mean', 'rank']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions with additional arguments\n",
    "\n",
    "Let's add some arguments to the function definition!\n",
    "\n",
    "Numeric data in scores represent students' performance scaled between 0 and 100. Your task is to rescale this data to an arbitrary range between low and high. Rescaling should be done in a linear fashion, i.e. for any data point x in a column:\n",
    "\n",
    "To do rescaling, you'll have to define the function rescale(). Remember, the operation written above can be applied to Series directly. After defining the function, you'll have to apply it to the specified columns of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(series, low, high):\n",
    "   # Define the expression to rescale input series\n",
    "   return series * ((high - low)/ 100) + low\n",
    "\n",
    "# Rescale the data in cols to lie between 1 and 10\n",
    "cols = ['math score', 'reading score', 'writing score'] \n",
    "scores[cols] = scores[cols].apply(rescale, args=[1,10] )\n",
    "print(scores[cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the function to accept keyword arguments\n",
    "def rescale(series, high=0, low=100):\n",
    "   return series * (high - low)/100 + low\n",
    "\n",
    "# Rescale the data in cols to lie between 1 and 10\n",
    "cols = ['math score', 'reading score', 'writing score']\n",
    "scores[cols] = scores[cols].apply(rescale, kwargs=[1,10])\n",
    "print(scores[cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the .groupby() method on a DataFrame?\n",
    "\n",
    "1. How to use the .groupby() method on a DataFrame?\n",
    "\n",
    "2. Dataset\n",
    "\n",
    "    We'll refer to the dataset on the relationship between personal background factors and the concentrations of plasma B-carotene and plasma retinol in blood. Low concentrations of these compounds have been suggested to be associated with a higher risk of cancer.\n",
    "\n",
    "3. .groupby()\n",
    "\n",
    "    The .groupby() method groups the data according to some criteria. We can then perform an operation on each group. The most common way is to group the data by a factor specified by a column name. For example, here we split by one factor, gender, and here - by two, gender and smoking. In both cases the output is a special DataFrameGroupBy object.\n",
    "\n",
    "    df.groupby(['gender', 'smoking'])\n",
    "\n",
    "4. Iterating through .groupby() output\n",
    "\n",
    "    It's possible to iterate through this object. Each item is a tuple with the first element being a grouping factor and the second - the corresponding DataFrame.\n",
    "\n",
    "    More grouping factors imply more DataFrames. Here, we get as many DataFrames as there are gender / smoking combinations.\n",
    "\n",
    "6. Standard operations on groups\n",
    "    \n",
    "    There are many cool things we can do with groups! For example, we already know that DataFrames and Series provide many standard methods to use. We can select a column and apply a method of interest. For example, .mean() or .count(). We can use the same functionality for groups! Here is the mean for each group. And here is the count of valid values for each group. \n",
    "\n",
    "        gens = retinol.groupby('gender')\n",
    "\n",
    "        gens['plasma retinol'].mean()\n",
    "        > gender    plasma retinol\n",
    "        > Female    587.721612\n",
    "        > Male      700.738095\n",
    "\n",
    "        gens['vitamin use'].count()\n",
    "        > gender    vitamin use\n",
    "        > Female    273\n",
    "        > Male      42\n",
    "        \n",
    "7. The .agg() method\n",
    "    \n",
    "    Actually, almost all the DataFrame or Series methods can be applied to DataFrameGroupBy objects. For example, let's recall the .agg() method. It's almost identical to the .apply() method we talked before. By default, it applies a function to each specified column that summarizes it with a single value. For example, to calculate the mean value of the plasma retinol level, we can pass the NumPy mean() function to the method.\n",
    "\n",
    "        retinol['plasma retinol'].agg(np.mean)\n",
    "        > 602.790476\n",
    "\n",
    "    The big difference to the .apply() method is that we can specify several aggregating functions in a list.\n",
    "\n",
    "        retinol[['plasma B-carotene', 'plasma retinol']].agg([np.mean, np.std])\n",
    "\n",
    "    As you might have guessed, the .agg() method can be successfully used for DataFrameGroupBy objects.\n",
    "\n",
    "        gensmoks = retinol.groupby(['gender', 'smoking'])\n",
    "        gensmoks['plasma retinol'].agg([np.mean, np.std])\n",
    "        \n",
    "11. Own functions and lambda expressions\n",
    "    \n",
    "    We can, of course, create our own functions. For example, let's count the number of values in a column exceeding the mean value. Here's the corresponding output.\n",
    "    We can also insert lambda expressions in the .agg() method. Here, we simply calculate the size of the column in a group.\n",
    "\n",
    "        gens[['plasma B-carotene', 'plasma retinol']].agg([n_more_than_mean, lambda x: len(x)])\n",
    "\n",
    "13. Renaming the output\n",
    "\n",
    "    If we use a dictionary instead of a list with functions, the keys will be used as column names.\n",
    "\n",
    "        gens[['plasma B-carotene', 'plasma retinol']].agg({'count': n_more_than_mean, 'len': lambda x: len(x)})\n",
    "\n",
    "14. The .transform() method\n",
    "    \n",
    "    Another useful DataFrame method is .transform(). It's also almost identical to the .apply() method we already discussed. It modifies the values in each given column by some rule specified in a function. For example, let's have a function that centers and scales the data in a column.\n",
    "\n",
    "        df.transform(function)\n",
    "\n",
    "15. DataFrame and the .transform() method\n",
    "\n",
    "    Here's the modified DataFrame after applying the .transform() method with our function on two columns.\n",
    "\n",
    "16. .groupby() followed by .transform()\n",
    "\n",
    "    If we apply the .transform() method on groups, the output will be different because we modify the columns in each group separately. Afterwards, the transformed data is merged into a single DataFrame.\n",
    "\n",
    "    Of course, instead of a well-defined function, we can also use a lambda expression.\n",
    "\n",
    "18. The .filter() method of DataFrameGroupBy object\n",
    "\n",
    "    The last method we discuss is the .filter() method. It filters out groups according to the logical output of the passed function and merges the remaining groups into a new DataFrame. Notice that a function acts on the whole DataFrame in each group. Therefore, we can specify quite complex filters.\n",
    "    \n",
    "        df.filter(funtion)\n",
    "\n",
    "19. .groupby() followed by .filter()\n",
    "\n",
    "    For example, when we group here, we get 6 groups. Let's have a function that checks if the mean BMI value is higher than 26. When we use it inside .filter(), we get the filtered DataFrame.\n",
    "\n",
    "        gensmoks = retinol.groupby(['gender', 'smoking'])        \n",
    "        len(gensmoks)\n",
    "        > 6\n",
    "        \n",
    "        def check_bmi(dataframe):\n",
    "            return np.mean(dataframe['bmi']) > 26\n",
    "            \n",
    "20. .groupby() followed by .filter()\n",
    "    \n",
    "    We can check how many groups were filtered out by grouping the filtered data again. Now we have only 3 groups instead of 6.\n",
    "\n",
    "        retinol_filtered = gensmoks.filter(check_bmi)\n",
    "        len(reitnol_filtered.groupby(['gender', 'smoking']))\n",
    "        > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard DataFrame methods\n",
    "\n",
    "You are given the diabetes dataset storing information on female patients tested for diabetes. You will focus on blood glucose levels and the test results. Subjects, tested positively, usually have higher blood glucose levels after performing the so-called glucose tolerance test. Your task is to investigate whether it is true for this specific dataset.\n",
    "\n",
    "The plasma glucose column corresponds to the glucose levels. The test result column corresponds to the diabetes test results.\n",
    "\n",
    "You must use standard DataFrame methods (the numpy module is not imported for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the diabetes.csv file\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "print(diabetes.info())\n",
    "\n",
    "# Calculate the mean glucose level in the entire dataset\n",
    "print(diabetes['plasma glucose'].mean())\n",
    "\n",
    "# Group the data according to the diabetes test results\n",
    "diabetes_grouped = diabetes.groupby('test result')\n",
    "\n",
    "import numpy\n",
    "# Calculate the mean glucose levels per group\n",
    "print(diabetes_grouped['plasma glucose'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI of villains\n",
    "\n",
    "Let's return to the heroes dataset containing the information on different comic book heroes. We added a bmi column to the dataset calculated as Weight divided by (Height/100)**2. This index helps define whether an individual has weight problems.\n",
    "\n",
    "Your task is to find out what is the mean value and standard deviation of the BMI index depending on the character's 'Alignment' and the 'Publisher' whom this character belongs to. However, you'll need to consider only those groups that have more than 10 valid observations of the BMI index.\n",
    "\n",
    "Tip: use .count() to calculate the number of valid observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Group the data by two factors specified in the context\n",
    "groups = heroes.groupby(['Alignment','Publisher'])\n",
    "\n",
    "# Filter groups having more than 10 valid bmi observations\n",
    "fheroes = groups.filter(lambda x: x['bmi'].count() > 10)\n",
    "\n",
    "# Group the filtered data again by the same factors\n",
    "fgroups = fheroes.groupby(['Alignment','Publisher'])\n",
    "\n",
    "# Calculate the mean and standard deviation of the BMI index\n",
    "result = fgroups['bmi'].agg([np.mean,np.std])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN value imputation\n",
    "\n",
    "Let's try to impute some values, using the .transform() method. In the previous task you created a DataFrame fheroes where all the groups with insufficient amount of bmi observations were removed. Our bmi column has a lot of missing values (NaNs) though. Given two copies of the fheroes DataFrame (imp_globmean and imp_grpmean), your task is to impute the NaNs in the bmi column with the overall mean value and with the mean value per group defined by Publisher and Alignment factors, respectively.\n",
    "\n",
    "Tip: pandas Series and NumPy arrays have a special .fillna() method which substitutes all the encountered NaNs with a value specified as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lambda function that imputes NaN values in series\n",
    "impute = lambda series: series.fillna(np.mean(series))\n",
    "\n",
    "# Impute NaNs in the bmi column of imp_globmean\n",
    "imp_globmean['bmi'] = imp_globmean['bmi'].transform(impute)\n",
    "print(\"Global mean = \" + str(fheroes['bmi'].mean()) + \"\\n\")\n",
    "\n",
    "groups = imp_grpmean.groupby(['Publisher', 'Alignment'])\n",
    "\n",
    "# Impute NaNs in the bmi column of imp_grpmean\n",
    "imp_grpmean['bmi'] = groups['bmi'].transform(impute)\n",
    "print(groups['bmi'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to visualize data in Python?\n",
    "\n",
    "2. matplotlib\n",
    "\n",
    "    The usual way to proceed is to use the matplotlib module. More precisely, to use its pyplot submodule. Usually, we abbreviate it as plt. We'll consider basic plots such as: scatter plot histogram and boxplot.\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "4. Scatter plot\n",
    "\n",
    "    Let's start with the scatter plot. It's a simple representation of data points in two-dimensional space, given that each point has valid coordinates. Scatter plot is very useful for examining how two numeric variables relate to each other.\n",
    "\n",
    "5. Create a scatter plot\n",
    "    \n",
    "    Given a DataFrame, we can create a scatter plot simply by inserting columns of interest in the scatter() function. The order is important: the first argument corresponds to the horizontal axis, the second - to the vertical one. To show the plot, we have to supply our script with the show() function. This function should always be at the end to complete our plotting activity. Now we see our scatter plot. Can you notice what's wrong with it? Right, it doesn't have neither a title nor labels, which is a very bad practice!\n",
    "\n",
    "        plt.scatter(x,y)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "6. Create a scatter plot\n",
    "\n",
    "    To add a title, we can use the title() function.\n",
    "\n",
    "        plt.title('')\n",
    "\n",
    "    To add labels for horizontal and vertical axes, we can use the xlabel() and ylabel() function, respectively. It's OK to skip the title, but NEVER forget to label your axes!\n",
    "\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel('')\n",
    "\n",
    "8. Histogram\n",
    "\n",
    "    Let's move on and meet the histogram! It's a special plot showing how our numerical data is distributed. The horizontal space is divided into so-called bins. The height of a bin indicates how many data points are enclosed in the horizontal space spanned by it. Here, for example, we see that the majority of data points is concentrated around 0.\n",
    "\n",
    "9. Create a histogram\n",
    "\n",
    "    Let's create a histogram showing the distribution of the BMI indices in our diabetes data. We need to call the hist() function with the chosen column as an argument.\n",
    "\n",
    "        plt.hist(x, bins=20)\n",
    "\n",
    "10. Create a histogram\n",
    "    \n",
    "    We can also change the amount of bins used to create a histogram. We just need to use the corresponding keyword argument.\n",
    "\n",
    "11. Boxplot\n",
    "    \n",
    "    Let's move on to boxplots! Like a histogram, a boxplot shows how our numerical data is distributed. Here, 50% of data points are located within the box with the orange line indicating the median value. In turn, the whiskers show the spread of our data. What is outside this range is considered as an outlier. As you can see, boxplots are great when we want to show if there is a difference between groups.\n",
    "\n",
    "12. Create a boxplot\n",
    "\n",
    "    To create a boxplot, it's much easier to use the seaborn module rather than the matplotlib. Usually, we abbreviate it as sns. To visualize the data, we have to use the boxplot() function. We have to specify the data source with the data keyword argument and the column names from this source. In this case, the first argument corresponds to the column with test results, which, as it is a factor, is responsible for the amount of boxplots we see. The second argument corresponds to the column with BMI indices, which represents the actual data for each boxplot.\n",
    "\n",
    "        import seaborn as sns\n",
    "\n",
    "        sns.boxplot('test_results', 'bmi', data=diabetes)\\\n",
    "        plt.title('Boxplots of BMI per test result')\n",
    "        plt.show()\n",
    "\n",
    "13. Create a boxplot\n",
    "    \n",
    "    We can precisely define what is plotted against horizontal x axis and against vertical y axis with the corresponding keyword arguments.\n",
    "\n",
    "14. Create a boxplot\n",
    "\n",
    "    Changing the order of keyword arguments rotates the boxplot. Finally, notice that with the seaborn module we don't need to specify our axis labels. It's done automatically!\n",
    "\n",
    "        sns.boxplot(y='test_result', x='bmi', data=diabetes)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a histogram\n",
    "\n",
    "Let's further investigate the retinol dataset. Your task now is to create a histogram of the plasma retinol feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(retinol['plasma retinol'], bins=20)\n",
    "plt.title('Histogram of Plasma Retinol')\n",
    "\n",
    "# Add other missing parts to the plot\n",
    "plt.xlabel('plasma retinol')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating boxplots\n",
    "\n",
    "Let's get back to our heroes dataset. As we previously discovered, the BMI index is in average much higher for villains than for good characters (taking into account only Marvel and DC publishers). Your task is to plot the corresponding distributions of BMI indices using boxplots.\n",
    "\n",
    "Tip: to select rows in a DataFrame, for which a specific column follows a certain condition, use this expression dataframe[condition for column_name] (e.g. heroes[heroes['Alignment'] == 'good'] selects rows that have a 'good' Alignment in the heroes dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Select rows from 'heroes' for which the BMI index < 1000\n",
    "heroes_filtered = heroes[heroes['bmi'] < 1000]\n",
    "\n",
    "# Create a new boxplot of BMI indices\n",
    "sns.boxplot(x='Alignment', y='bmi', data=heroes_filtered)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
